{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGå®Ÿè¡Œãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ (v2: ã‚¯ãƒ©ã‚¹ãƒ™ãƒ¼ã‚¹)\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€FAQãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦RAGå‡¦ç†ã‚’å®Ÿè¡Œã—ã€\n",
    "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€LLMå›ç­”ç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚\n",
    "\n",
    "**å‰ææ¡ä»¶**:\n",
    "- `.env`ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¨­å®šæ¸ˆã¿ï¼ˆDBæ¥ç¶šã€OCIèªè¨¼æƒ…å ±ï¼‰\n",
    "- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆsource_documents, chunksï¼‰ãŒä½œæˆæ¸ˆã¿\n",
    "- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²æ¸ˆã¿ï¼ˆ12_data_pipeline_v2.ipynbå®Ÿè¡Œæ¸ˆã¿ï¼‰\n",
    "- Object Storageã«FAQãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "###  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ   ###\n",
    "####################################\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ \n",
    "# notebooksãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹å ´åˆã€è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"âœ“ Project root added to Python path: {project_root}\")\n",
    "\n",
    "\n",
    "####################################\n",
    "########  å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¾¤ ##########\n",
    "####################################\n",
    "\n",
    "# æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Oracle Database\n",
    "import oracledb\n",
    "\n",
    "# è¨­å®šèª­ã¿è¾¼ã¿\n",
    "from config_loader import ConfigLoader\n",
    "\n",
    "# RAGå‡¦ç†ã‚¯ãƒ©ã‚¹\n",
    "from src.rag.vector_searcher import VectorSearcher\n",
    "from src.rag.reranker import JapaneseReranker\n",
    "from src.rag.answer_generator import AnswerGenerator\n",
    "from src.rag.ragas_evaluator import RagasEvaluator\n",
    "from src.rag.excel_handler import ExcelHandler\n",
    "from src.rag.rag_pipeline import RAGPipeline\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. è¨­å®šã®èª­ã¿è¾¼ã¿ã¨DBæ¥ç¶š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#  è¨­å®šã¨æ¥ç¶š  #\n",
    "################\n",
    "\n",
    "# ConfigLoaderã‚’ä½¿ç”¨ã—ã¦è¨­å®šã‚’èª­ã¿è¾¼ã¿\n",
    "config = ConfigLoader()\n",
    "config.load_env()\n",
    "\n",
    "# Oracle Databaseæ¥ç¶š\n",
    "db_params = config.get_db_params()\n",
    "connection = oracledb.connect(**db_params)\n",
    "\n",
    "# OCIè¨­å®š\n",
    "oci_config = config.get_oci_config()\n",
    "\n",
    "# GenAIè¨­å®š\n",
    "genai_config = config.get_genai_config()\n",
    "compartment_id = genai_config['compartment_id']\n",
    "embedding_model = genai_config['embed_model']\n",
    "\n",
    "# Object Storageè¨­å®š\n",
    "os_config = config.get_object_storage_config()\n",
    "bucket_name = os_config['bucket_name']\n",
    "\n",
    "# Object Storageã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã—ã¦namespaceã‚’å–å¾—\n",
    "os_client = config.get_object_storage_client()\n",
    "namespace = os_client.get_namespace().data\n",
    "\n",
    "# GenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆå…±é€šï¼‰\n",
    "genai_client = config.get_genai_client()\n",
    "\n",
    "print(f\"âœ“ OCIãƒªã‚½ãƒ¼ã‚¹ã®æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "print(f\"  - Database: {connection}\")\n",
    "print(f\"  - Bucket: {bucket_name}\")\n",
    "print(f\"  - Namespace: {namespace}\")\n",
    "print(f\"  - Compartment ID: {compartment_id[:20]}...\")\n",
    "print(f\"  - Embedding Model: {embedding_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAGãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ç·¨é›†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "############################\n#  RAGãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š  #\n############################\n\n# ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\nTOP_K = 10  # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä¸Šä½ä½•ä»¶ã‚’è¿”å´ã™ã‚‹ã‹ã€‚Rerankç„¡åŠ¹æ™‚ã¯ã“ã®å€¤ãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»¶æ•°\n\n# Rerankã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Rerankã¯CPUå‡¦ç†æ€§èƒ½ã«ä¾ã£ã¦ã¯é•·æ™‚é–“è¦ã™ã‚‹ãŸã‚æ³¨æ„)\nRERANK_ENABLED = True  # True or False\nRERANK_TOP_N = 5  # Rerankå¾Œã«ä¸Šä½ä½•ä»¶ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã‹\n\n# LLMé¸æŠãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n# ä»¥ä¸‹ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„ï¼š\n# ã€Cohereã€‘ \"cohere.command-a-03-2025\", \"cohere.command-r-plus-08-2024\"\n# ã€Meta Llamaã€‘ \"meta.llama-3.3-70b-instruct\"\n# ã€xAI Grokã€‘ \"xai.grok-4-fast-non-reasoning\", \"xai.grok-4-fast-reasoning\", \"xai.grok-4\"\n# ã€Google Geminiã€‘ \"google.gemini-2.5-pro\", \"google.gemini-2.5-flash\", \"google.gemini-2.5-flash-lite\"\n# ã€OpenAI GPT-OSSã€‘ \"openai.gpt-oss-20b\", \"openai.gpt-oss-120b\"\nCHAT_MODEL = \"cohere.command-a-03-2025\"  # ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š\n\n# LLMãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\nMAX_TOKENS = 1000  # ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°\nTEMPERATURE = 0.3  # æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ0-1ã€å‰µé€ æ€§ã®åˆ¶å¾¡ã€‚0ã«è¿‘ã„ã»ã©æ±ºå®šçš„ã€1ã«è¿‘ã„ã»ã©ãƒ©ãƒ³ãƒ€ãƒ ï¼‰\nTOP_P = 0.75  # Nucleus samplingã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ0-1ï¼‰\nFREQUENCY_PENALTY = 0.0  # é »åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆCohereç”¨ã€0-1ã€‚ç¹°ã‚Šè¿”ã—ã‚’æŠ‘åˆ¶ï¼‰\nTOP_K_SAMPLING = 0  # Top-Kã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆCohereç”¨ã€0ã§ç„¡åŠ¹ï¼‰\n\n# å›ç­”ç”Ÿæˆæ™‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\nANSWER_PROMPT = \"\"\"\nå‚è€ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æƒ…å ±ã«åŸºã¥ã„ã¦ã€æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æƒ…å ±ãŒãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚\nå›ç­”ã¯ç°¡æ½”ã«å¹³æ–‡ã§è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚\n\"\"\"\n\n# FAQãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: faq.xlsxï¼‰\nFAQ_OBJECT_NAME = config.get_faq_object_name()\n\nprint(f\"âœ“ RAGãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå€¤\")\nprint(f\"  - Vector Search TOP_K: {TOP_K}\")\nprint(f\"  - Rerank Enabled: {RERANK_ENABLED}\")\nprint(f\"  - Rerank TOP_N: {RERANK_TOP_N}\")\nprint(f\"  - Chat Model: {CHAT_MODEL}\")\nprint(f\"  - Max Tokens: {MAX_TOKENS}\")\nprint(f\"  - Temperature: {TEMPERATURE}\")\nprint(f\"  - FAQ File: {FAQ_OBJECT_NAME}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ï¼ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã¨ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ä½œæˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "############################\n#  RAGã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–  # \n############################\n\n# Phase 1: VectorSearcherï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰\nsearcher = VectorSearcher(\n    db_params=db_params,\n    embedding_model=embedding_model,\n    genai_client=genai_client,\n    compartment_id=compartment_id,\n    service_endpoint=genai_config['endpoint']\n)\n\n# Phase 2: JapaneseRerankerï¼ˆãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰\n# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¨ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡ºã¯è‡ªå‹•\nprint(\"\\nInitializing JapaneseReranker...\")\nreranker = JapaneseReranker()\nprint(\"âœ“ JapaneseReranker initialized\")\n\n# Phase 3: AnswerGeneratorï¼ˆLLMå›ç­”ç”Ÿæˆï¼‰\ngenerator = AnswerGenerator(\n    genai_client=genai_client,\n    compartment_id=compartment_id\n)\n\n# Phase 4: RagasEvaluatorï¼ˆRAGASè©•ä¾¡ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n# åŸºæœ¬ç‰ˆã§ã¯ None ã«ã—ã¦ã€è©•ä¾¡ã¯åˆ¥ã‚»ãƒ«ã§å®Ÿè¡Œ\nevaluator = None\n\n# Phase 5: ExcelHandlerï¼ˆObject Storage I/Oï¼‰\n# FAQç”¨ã®ãƒã‚±ãƒƒãƒˆåã‚’å–å¾—ï¼ˆOCI_FAQ_BUCKET_NAMEã¾ãŸã¯OCI_BUCKET_NAMEï¼‰\nfaq_bucket_name = config.get_faq_bucket_name()\nexcel_handler = ExcelHandler(\n    oci_config=oci_config,\n    bucket_name=faq_bucket_name,\n    namespace=namespace\n)\n\nprint(\"\\nâœ“ All 5 components initialized\")\nprint(f\"  1. VectorSearcher (model: {embedding_model})\")\nprint(f\"  2. JapaneseReranker (model: hotchpotch/japanese-reranker-base-v2)\")\nprint(f\"  3. AnswerGenerator (compartment: {compartment_id[:20]}...)\")\nprint(f\"  4. RagasEvaluator (skipped for now)\")\nprint(f\"  5. ExcelHandler (bucket: {faq_bucket_name}, namespace: {namespace})\")\n\n\n############################\n#  ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯  # \n############################\n\ndef progress_callback(message: str):\n    \"\"\"\n    å‡¦ç†é€²æ—ã‚’è¡¨ç¤º\n    \n    Args:\n        message: é€²æ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n    \"\"\"\n    print(f\"  {message}\")\n\n\n############################\n#  RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿  # \n############################\n\n# Phase 6: RAGPipelineï¼ˆå…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆï¼‰\npipeline = RAGPipeline(\n    searcher=searcher,\n    reranker=reranker,\n    generator=generator,\n    evaluator=evaluator,  # None\n    enable_reranking=RERANK_ENABLED,\n    top_k=TOP_K,\n    rerank_top_n=RERANK_TOP_N,\n    progress_callback=progress_callback\n)\n\nprint(\"\\nâœ“ RAGPipeline orchestrator created\")\nprint(f\"  - Reranking: {'Enabled' if RERANK_ENABLED else 'Disabled'}\")\nprint(f\"  - Vector search top_k: {TOP_K}\")\nprint(f\"  - Rerank top_n: {RERANK_TOP_N}\")\nprint(\"  - Error isolation enabled (individual question failures won't stop processing)\")\nprint(\"  - Progress tracking enabled\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FAQãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#  FAQãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿  # \n",
    "############################\n",
    "\n",
    "# Object Storageã‹ã‚‰FAQãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
    "faq_df = excel_handler.load_faq(FAQ_OBJECT_NAME)\n",
    "\n",
    "print(f\"âœ“ FAQ file loaded: {len(faq_df)} questions\")\n",
    "print(f\"\\nFAQ Data Preview:\")\n",
    "print(faq_df[['id', 'question', 'ground_truth', 'filter']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RAGå‡¦ç†å®Ÿè¡Œï¼ˆå›ç­”ç”Ÿæˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# ãƒ¡ã‚¤ãƒ³å‡¦ç† #\n",
    "############\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting RAG Processing...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(f\"Total questions: {len(faq_df)}\")\n",
    "print(f\"Model: {CHAT_MODEL}\\n\")\n",
    "\n",
    "# ã™ã¹ã¦ã®è³ªå•ã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†\n",
    "# process_batch()ã¯å„è³ªå•ã‚’é †æ¬¡å‡¦ç†ã—ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ç¶™ç¶š\n",
    "batch_result = pipeline.process_batch(\n",
    "    questions_df=faq_df,\n",
    "    model=CHAT_MODEL,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    "    top_p=TOP_P,\n",
    "    frequency_penalty=FREQUENCY_PENALTY,\n",
    "    top_k=TOP_K_SAMPLING,\n",
    "    answer_prompt=ANSWER_PROMPT\n",
    ")\n",
    "\n",
    "# å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Processing Complete\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Š Summary:\")\n",
    "print(f\"  âœ“ Success: {batch_result.successful} questions\")\n",
    "print(f\"  âœ— Failed:  {batch_result.failed} questions\")\n",
    "print(f\"  ğŸ“ Total:   {batch_result.total_questions} questions\")\n",
    "print(f\"  â±ï¸ Time:    {batch_result.elapsed_time:.2f} seconds\")\n",
    "print(f\"  ğŸ“ˆ Avg:     {batch_result.elapsed_time/batch_result.total_questions:.2f} seconds/question\")\n",
    "\n",
    "# å‡¦ç†æ™‚é–“ã®çµ±è¨ˆã‚’è¡¨ç¤º\n",
    "results_df = batch_result.results_df\n",
    "print(f\"\\nã€å‡¦ç†æ™‚é–“ã®çµ±è¨ˆã€‘\")\n",
    "print(f\"  ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢å¹³å‡: {results_df['vector_search_time'].mean():.2f}ç§’\")\n",
    "print(f\"  Rerankå¹³å‡: {results_df['rerank_time'].mean():.2f}ç§’\")\n",
    "print(f\"  å›ç­”ç”Ÿæˆå¹³å‡: {results_df['generation_time'].mean():.2f}ç§’\")\n",
    "print(f\"  åˆè¨ˆå¹³å‡: {results_df['total_time'].mean():.2f}ç§’\")\n",
    "\n",
    "# çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º\n",
    "print(f\"\\nğŸ“‹ Results Preview:\")\n",
    "print(results_df[['id', 'question', 'answer', 'total_time', 'status']].head())\n",
    "\n",
    "# å¤±æ•—ã—ãŸè³ªå•ãŒã‚ã‚Œã°è­¦å‘Š\n",
    "if batch_result.failed > 0:\n",
    "    print(f\"\\nâš  Warning: {batch_result.failed} questions failed to process\")\n",
    "    failed_df = results_df[results_df['status'] == 'failed']\n",
    "    print(\"\\nFailed questions:\")\n",
    "    print(failed_df[['id', 'question', 'error']])\n",
    "\n",
    "\n",
    "############################\n",
    "#  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ  # \n",
    "############################\n",
    "\n",
    "# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å«ã‚€ï¼‰\n",
    "metadata = {\n",
    "    'ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿': [\n",
    "        'TOP_K (ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ä»¶æ•°)',\n",
    "        'RERANK_ENABLED (RerankãŒæœ‰åŠ¹ã‹)',\n",
    "        'RERANK_TOP_N (Rerankå¾Œä»¶æ•°)',\n",
    "        'CHAT_MODEL (ä½¿ç”¨LLMãƒ¢ãƒ‡ãƒ«)',\n",
    "        'MAX_TOKENS (æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°)',\n",
    "        'TEMPERATURE (æ¸©åº¦)',\n",
    "        'TOP_P (Nucleus sampling)',\n",
    "        'FREQUENCY_PENALTY (é »åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£)',\n",
    "        'TOP_K_SAMPLING (Top-K sampling)',\n",
    "        'ANSWER_PROMPT (å›ç­”ç”Ÿæˆæ™‚ã®æŒ‡ç¤ºæ–‡)',\n",
    "        'embedding_model',\n",
    "        'rerank_model',\n",
    "        'å®Ÿè¡Œæ—¥æ™‚',\n",
    "        'FAQä»¶æ•°',\n",
    "        'æˆåŠŸä»¶æ•°',\n",
    "        'å¤±æ•—ä»¶æ•°',\n",
    "        'å…¨ä½“å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰',\n",
    "        'å¹³å‡å‡¦ç†æ™‚é–“/ä»¶ï¼ˆç§’ï¼‰',\n",
    "        'ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢å¹³å‡æ™‚é–“ï¼ˆç§’ï¼‰',\n",
    "        'Rerankå¹³å‡æ™‚é–“ï¼ˆç§’ï¼‰',\n",
    "        'å›ç­”ç”Ÿæˆå¹³å‡æ™‚é–“ï¼ˆç§’ï¼‰'\n",
    "    ],\n",
    "    'è¨­å®šå€¤': [\n",
    "        TOP_K,\n",
    "        RERANK_ENABLED,\n",
    "        RERANK_TOP_N,\n",
    "        CHAT_MODEL,\n",
    "        MAX_TOKENS,\n",
    "        TEMPERATURE,\n",
    "        TOP_P,\n",
    "        FREQUENCY_PENALTY,\n",
    "        TOP_K_SAMPLING,\n",
    "        ANSWER_PROMPT,\n",
    "        embedding_model,\n",
    "        'hotchpotch/japanese-reranker-base-v2',\n",
    "        datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        batch_result.total_questions,\n",
    "        batch_result.successful,\n",
    "        batch_result.failed,\n",
    "        f\"{batch_result.elapsed_time:.2f}\",\n",
    "        f\"{batch_result.elapsed_time/batch_result.total_questions:.2f}\",\n",
    "        f\"{results_df['vector_search_time'].mean():.2f}\",\n",
    "        f\"{results_df['rerank_time'].mean():.2f}\",\n",
    "        f\"{results_df['generation_time'].mean():.2f}\"\n",
    "    ]\n",
    "}\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "\n",
    "############################\n",
    "#  Object Storageã¸ä¿å­˜  # \n",
    "############################\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_filename = f\"rag_result_{timestamp}.xlsx\"\n",
    "\n",
    "# Object Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãï¼‰\n",
    "print(f\"\\nğŸ“¤ Saving results to Object Storage...\")\n",
    "excel_handler.save_results(\n",
    "    results_df=results_df,\n",
    "    filename=output_filename,\n",
    "    metadata_df=metadata_df\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Results saved successfully\")\n",
    "print(f\"  - Bucket: {bucket_name}\")\n",
    "print(f\"  - Filename: {output_filename}\")\n",
    "print(f\"  - Rows: {len(results_df)}\")\n",
    "print(f\"  - Sheets: Results, Settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DBæ¥ç¶šã®ã‚¯ãƒ­ãƒ¼ã‚º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#  å¾Œå‡¦ç†  # \n",
    "################\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’æ˜ç¤ºçš„ã«ã‚¯ãƒ­ãƒ¼ã‚º\n",
    "connection.close()\n",
    "print(\"âœ“ Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}